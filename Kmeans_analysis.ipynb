{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c111761b-b244-4b76-9192-f4b6edf328a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\achan\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.4.1.post1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: threadpoolctl in c:\\users\\achan\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Collecting threadpoolctl\n",
      "  Using cached threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\achan\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\achan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\achan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Using cached scikit_learn-1.4.1.post1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "Using cached threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 2.2.0\n",
      "    Uninstalling threadpoolctl-2.2.0:\n",
      "      Successfully uninstalled threadpoolctl-2.2.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.0\n",
      "    Uninstalling scikit-learn-1.3.0:\n",
      "      Successfully uninstalled scikit-learn-1.3.0\n",
      "Successfully installed scikit-learn-1.4.1.post1 threadpoolctl-3.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping C:\\Users\\achan\\anaconda3\\Lib\\site-packages\\fqdn-1.5.1.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\achan\\anaconda3\\Lib\\site-packages\\fqdn-1.5.1.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\achan\\anaconda3\\Lib\\site-packages\\fqdn-1.5.1.dist-info due to invalid metadata entry 'name'\n",
      "    WARNING: Skipping C:\\Users\\achan\\anaconda3\\Lib\\site-packages\\fqdn-1.5.1.dist-info due to invalid metadata entry 'name'\n",
      "    WARNING: Skipping C:\\Users\\achan\\anaconda3\\Lib\\site-packages\\fqdn-1.5.1.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\achan\\anaconda3\\Lib\\site-packages\\fqdn-1.5.1.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\achan\\anaconda3\\Lib\\site-packages\\fqdn-1.5.1.dist-info due to invalid metadata entry 'name'\n",
      "WARNING: Skipping C:\\Users\\achan\\anaconda3\\Lib\\site-packages\\fqdn-1.5.1.dist-info due to invalid metadata entry 'name'\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade scikit-learn threadpoolctl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe63f63-d391-4de8-9dfb-898376db7c31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achan\\OneDrive\\Desktop\\Term Project Data\n"
     ]
    }
   ],
   "source": [
    "# set workspace\n",
    "WhoIsWorking = \"AA\"\n",
    "WorkLocation = \"School\"\n",
    "\n",
    "if WhoIsWorking == \"RT\":\n",
    "    if WorkLocation == \"Home\":\n",
    "        folder_path = r'C:\\Users\\rentr\\Desktop\\ENGO\\DataMining\\ENGO645_TermProject_Data'\n",
    "    elif WorkLocation == \"School\":\n",
    "        folder_path = r'D:\\ENGO645_TermProject_Data'\n",
    "elif WhoIsWorking == \"AA\":\n",
    "    folder_path = r'C:\\Users\\achan\\OneDrive\\Desktop\\Term Project Data'\n",
    "elif WhoIsWorking == \"IA\":\n",
    "    folder_path = r'C:\\Users\\afoam\\assignments\\ENGO645_TorontoCrimeAnalysis'\n",
    "elif WhoIsWorking == \"AI\":\n",
    "    folder_path = r'C:\\Adewale_Directory\\Capacity_Building\\MGIS\\Lecture_Note\\WINTER2024\\ENGO645\\Course_Project\\Project_Data'\n",
    "\n",
    "print(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c71a8034-9259-4f8b-859a-3dfbfef2721c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 geometry  \\\n",
      "101225  POLYGON ((-79.3526822361769 43.655714324394, -...   \n",
      "101226  POLYGON ((-79.3526822361769 43.655714324394, -...   \n",
      "101227  POLYGON ((-79.3526822361769 43.655714324394, -...   \n",
      "101228  POLYGON ((-79.3526822361769 43.655714324394, -...   \n",
      "101229  POLYGON ((-79.3526822361769 43.655714324394, -...   \n",
      "...                                                   ...   \n",
      "264385  POLYGON ((-79.3452871691637 43.7528896509851, ...   \n",
      "264386  POLYGON ((-79.3452871691637 43.7528896509851, ...   \n",
      "264387  POLYGON ((-79.3452871691637 43.7528896509851, ...   \n",
      "264388  POLYGON ((-79.3452871691637 43.7528896509851, ...   \n",
      "264389  POLYGON ((-79.3452871691637 43.7528896509851, ...   \n",
      "\n",
      "                            NeighbourhoodName  Poles_Count  POI_Count  \\\n",
      "101225  St Lawrence-East Bayfront-The Islands         1968       1513   \n",
      "101226  St Lawrence-East Bayfront-The Islands         1968       1513   \n",
      "101227  St Lawrence-East Bayfront-The Islands         1968       1513   \n",
      "101228  St Lawrence-East Bayfront-The Islands         1968       1513   \n",
      "101229  St Lawrence-East Bayfront-The Islands         1968       1513   \n",
      "...                                       ...          ...        ...   \n",
      "264385                      Banbury-Don Mills         3266       1670   \n",
      "264386                      Banbury-Don Mills         3266       1670   \n",
      "264387                      Banbury-Don Mills         3266       1670   \n",
      "264388                      Banbury-Don Mills         3266       1670   \n",
      "264389                      Banbury-Don Mills         3266       1670   \n",
      "\n",
      "        TCamera_Count  TotalPopulation  MedianTotalIncome  AverageTotalIncome  \\\n",
      "101225             20            31285              58000               79700   \n",
      "101226             20            31285              58000               79700   \n",
      "101227             20            31285              58000               79700   \n",
      "101228             20            31285              58000               79700   \n",
      "101229             20            31285              58000               79700   \n",
      "...               ...              ...                ...                 ...   \n",
      "264385              6            27155              46400               77800   \n",
      "264386              6            27155              46400               77800   \n",
      "264387              6            27155              46400               77800   \n",
      "264388              6            27155              46400               77800   \n",
      "264389              6            27155              46400               77800   \n",
      "\n",
      "        BuildingCoveragePERCENTAGE  ParksOSNAPERCENTAGE  ...          OFFENCE  \\\n",
      "101225                    5.626073            31.284177  ...  Robbery - Other   \n",
      "101226                    5.626073            31.284177  ...          Assault   \n",
      "101227                    5.626073            31.284177  ...          Assault   \n",
      "101228                    5.626073            31.284177  ...              B&E   \n",
      "101229                    5.626073            31.284177  ...          Assault   \n",
      "...                            ...                  ...  ...              ...   \n",
      "264385                   15.576397            17.956461  ...     B&E W'Intent   \n",
      "264386                   15.576397            17.956461  ...     B&E W'Intent   \n",
      "264387                   15.576397            17.956461  ...              B&E   \n",
      "264388                   15.576397            17.956461  ...              B&E   \n",
      "264389                   15.576397            17.956461  ...          Assault   \n",
      "\n",
      "           MCI_CATEGORY                      NEIGHBOURHOOD_158 LONG_WGS84  \\\n",
      "101225          Robbery  St Lawrence-East Bayfront-The Islands -79.368457   \n",
      "101226          Assault  St Lawrence-East Bayfront-The Islands -79.379088   \n",
      "101227          Assault  St Lawrence-East Bayfront-The Islands -79.379088   \n",
      "101228  Break and Enter  St Lawrence-East Bayfront-The Islands -79.357357   \n",
      "101229          Assault  St Lawrence-East Bayfront-The Islands -79.373776   \n",
      "...                 ...                                    ...        ...   \n",
      "264385  Break and Enter                      Banbury-Don Mills -79.327552   \n",
      "264386  Break and Enter                      Banbury-Don Mills -79.327552   \n",
      "264387  Break and Enter                      Banbury-Don Mills -79.350149   \n",
      "264388  Break and Enter                      Banbury-Don Mills -79.327552   \n",
      "264389          Assault                      Banbury-Don Mills -79.349556   \n",
      "\n",
      "        LAT_WGS84  DATE_TIME_LINK TIMECategory  TEMP TEMPCategory Cluster  \n",
      "101225  43.648776      2023/1/1 1        Night   4.5         Mild       2  \n",
      "101226  43.645917      2023/1/1 8      Morning   4.2         Mild       2  \n",
      "101227  43.645917      2023/1/1 8      Morning   4.2         Mild       2  \n",
      "101228  43.651340     2023/1/1 20      Evening   4.0         Mild       2  \n",
      "101229  43.648437     2023/1/3 20      Evening   3.7         Mild       2  \n",
      "...           ...             ...          ...   ...          ...     ...  \n",
      "264385  43.726641   2014/12/18 14    Afternoon   0.3         Mild       2  \n",
      "264386  43.726641   2014/12/22 16    Afternoon   1.1         Mild       2  \n",
      "264387  43.719590   2014/12/23 12    Afternoon   4.7         Mild       2  \n",
      "264388  43.726641    2014/12/28 6      Morning   2.9         Mild       2  \n",
      "264389  43.751793    2014/12/30 6      Morning  -6.0       Chilly       2  \n",
      "\n",
      "[23887 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the data\n",
    "neighbourhood_data = pd.read_csv(r\"C:\\Users\\achan\\OneDrive\\Desktop\\Term Project Data\\Neighbourhood_Cleaned.csv\")\n",
    "crime_data = pd.read_csv(r\"C:\\Users\\achan\\OneDrive\\Desktop\\Term Project Data\\MCI_Cleaned.csv\")\n",
    "\n",
    "# Merge the two datasets on the neighbourhood column\n",
    "merged_data = pd.merge(neighbourhood_data, crime_data, left_on='NeighbourhoodName', right_on='NEIGHBOURHOOD_158')\n",
    "\n",
    "# Select the columns to use for clustering\n",
    "columns = ['Poles_Count', 'POI_Count', 'TCamera_Count', 'TotalPopulation', 'MedianTotalIncome', 'AverageTotalIncome', 'BuildingCoveragePERCENTAGE', 'ParksOSNAPERCENTAGE', 'BuiltUpPERCENTAGE', 'AveragePrice', 'OCC_YEAR', 'OCC_HOUR', 'TEMP']\n",
    "data_for_clustering = merged_data[columns]\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data_imputed = imputer.fit_transform(data_for_clustering)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_imputed)\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=0)  \n",
    "clusters = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "# Add the cluster labels to the original data\n",
    "merged_data['Cluster'] = clusters\n",
    "\n",
    "# Identify the high-risk areas\n",
    "high_risk_areas = merged_data[merged_data['Cluster'] == merged_data['Cluster'].value_counts().idxmin()]\n",
    "\n",
    "print(high_risk_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a175f5-4aa8-4523-ba80-19ae83424ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\achan\\AppData\\Local\\Temp\\ipykernel_6912\\2149622241.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_neighbourhood.dropna(inplace=True)\n",
      "C:\\Users\\achan\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'NEIGHBOURHOOD_158'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6912\\2149622241.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;31m# Group crime data by neighbourhood and count the number of crimes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mcrime_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures_crime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NEIGHBOURHOOD_158'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Crime_Count'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# Merge crime counts with neighbourhood data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mneighbourhood_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneighbourhood_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrime_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NEIGHBOURHOOD_158'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# Output clusters and crime counts for high-risk areas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mhigh_risk_areas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneighbourhood_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NeighbourhoodName'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Cluster'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Crime_Count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10801\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10802\u001b[0m     ) -> DataFrame:\n\u001b[0;32m  10803\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10805\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m  10806\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10807\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10808\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         )\n\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         op = _MergeOperation(\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1306\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1310\u001b[1;33m                         \u001b[0mleft_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1311\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m                         \u001b[1;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1906\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1907\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1908\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1910\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1912\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'NEIGHBOURHOOD_158'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "neighbourhood_data = pd.read_csv(r\"C:\\Users\\achan\\OneDrive\\Desktop\\Term Project Data\\Neighbourhood_Cleaned.csv\")\n",
    "crime_data = pd.read_csv(r\"C:\\Users\\achan\\OneDrive\\Desktop\\Term Project Data\\MCI_Cleaned.csv\")\n",
    "\n",
    "# Select relevant features for clustering\n",
    "features_neighbourhood = neighbourhood_data[['Poles_Count', 'POI_Count', 'TCamera_Count', 'TotalPopulation', \n",
    "                                             'MedianTotalIncome', 'AverageTotalIncome', 'BuildingCoveragePERCENTAGE', \n",
    "                                             'ParksOSNAPERCENTAGE', 'BuiltUpPERCENTAGE', 'AveragePrice']]\n",
    "\n",
    "# Drop rows with missing values\n",
    "features_neighbourhood.dropna(inplace=True)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "scaled_features_neighbourhood = scaler.fit_transform(features_neighbourhood)\n",
    "\n",
    "# Perform k-means clustering\n",
    "k = 5  # Number of clusters\n",
    "kmeans_neighbourhood = KMeans(n_clusters=k, random_state=42)\n",
    "clusters_neighbourhood = kmeans_neighbourhood.fit_predict(scaled_features_neighbourhood)\n",
    "\n",
    "# Add cluster labels to the neighbourhood data\n",
    "neighbourhood_data['Cluster'] = clusters_neighbourhood\n",
    "\n",
    "# Select relevant features for crime data\n",
    "features_crime = crime_data[['NEIGHBOURHOOD_158', 'LAT_WGS84', 'LONG_WGS84']]\n",
    "\n",
    "# Group crime data by neighbourhood and count the number of crimes\n",
    "crime_counts = features_crime.groupby('NEIGHBOURHOOD_158').size().reset_index(name='Crime_Count')\n",
    "\n",
    "# Merge crime counts with neighbourhood data\n",
    "neighbourhood_data = neighbourhood_data.merge(crime_counts, on='NEIGHBOURHOOD_158', how='left')\n",
    "\n",
    "# Output clusters and crime counts for high-risk areas\n",
    "high_risk_areas = neighbourhood_data[['NeighbourhoodName', 'Cluster', 'Crime_Count']]\n",
    "high_risk_areas.to_csv(\"High_Risk_Areas.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce39127-51dc-48cb-b25b-19c7438795b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
